{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing packages:\n",
    "from skimage.segmentation import slic,mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "from skimage.measure import regionprops\n",
    "from skimage.color import rgb2hsv\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedShuffleSplit,KFold,ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "import cv2 as cv \n",
    "import os,glob, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "imagename= \"horse/rgb/horse001.jpg\"\n",
    "labeling= \"horse/figure_ground/horse001.jpg\"\n",
    "n_segments =10\n",
    "sigma = 5 \n",
    "def preprocessing(imagename, labeling,n_segments,sigma):\n",
    "    # load the image and convert it to a floating point data type\n",
    "    image= img_as_float(io.imread(imagename))\n",
    "    #load the image with the labeling\n",
    "    imlabels= cv.imread(labeling)\n",
    "    imlabels= cv.resize(imlabels,(image.shape[1],image.shape[0]))\n",
    "    # Perform slic super pixels segmentations\n",
    "    segments = slic(image, n_segments = n_segments, sigma = sigma)\n",
    "    regionpro=regionprops(segments,imlabels[:,:,1])\n",
    "    prob=np.array([p.mean_intensity/255 for p in regionpro])\n",
    "    prob = np.insert(prob, 0, [0])\n",
    "    labels=[0 if i<0.5 else 1 for i in prob]\n",
    "    return image,segments,labels\n",
    "\n",
    "def make3d(descriptor):\n",
    "    if (descriptor.ndim==2):\n",
    "        dim=1\n",
    "    else:\n",
    "        dim=descriptor.shape[2]\n",
    "    return np.reshape(descriptor, (descriptor.shape[0],descriptor.shape[1],dim))\n",
    "\n",
    "\n",
    "def compute_polling(plane, segments):\n",
    "    numsegments = int(np.max(segments)+1)\n",
    "    fv = np.zeros((5,numsegments))\n",
    "    fv[3,:] = np.max(plane)\n",
    "    fv[4,:] = np.min(plane)\n",
    "    for y in range(plane.shape[0]):\n",
    "        for x in range(plane.shape[1]):\n",
    "            L = int(segments[y,x])\n",
    "            V = plane[y,x]\n",
    "            fv[0,L] = fv[0,L]+1\n",
    "            fv[1,L] = fv[1,L]+V\n",
    "            fv[2,L] = fv[2,L]+V**2\n",
    "            fv[3,L] = min(fv[3,L],V)\n",
    "            fv[4,L] = max(fv[4,L],V)\n",
    "    #for L in range(numsegments):\n",
    "    fv[1,:] = fv[1,:]/fv[0,:]\n",
    "    fv[2,:] = fv[2,:]-fv[1,:]**2\n",
    "    fv[np.isnan(fv)] = 0\n",
    "    return fv\n",
    "\n",
    "\n",
    "def build_features(image, segments):\n",
    "    hsv = rgb2hsv(image)\n",
    "    h=hsv[:,:,0]/180\n",
    "    s=hsv[:,:,1]/255\n",
    "    v=hsv[:,:,2]/255\n",
    "    ga=cv.GaussianBlur(image,(61,61),8.0)\n",
    "    laga=cv.Laplacian(ga,cv.CV_64F)\n",
    "    sobel= cv.Sobel(image,cv.CV_64F,1,0,ksize=3)\n",
    "    descriptors=[image,h,s,v,ga,laga,sobel]  \n",
    "    dataset=np.zeros((5,segments.max()+1))\n",
    "    count=0\n",
    "    for descriptor in descriptors:\n",
    "        descriptor = make3d(descriptor)\n",
    "        for channel in range(0,descriptor.shape[2]):\n",
    "            plane = descriptor[:,:,channel]\n",
    "            fv=compute_polling(plane,segments)\n",
    "            dataset=np.r_[dataset,fv]\n",
    "    return dataset\n",
    "\n",
    "def build_dataset(imagespath,labelingpath):\n",
    "    imlist = glob.glob(os.path.join(imagespath,'*.jpg'))\n",
    "    data  = np.ndarray((0,80))\n",
    "    labeling = []\n",
    "    for im in imlist[0:20]:\n",
    "        image,segments,labels = preprocessing(im,labelingpath+im[10:],n_segments,sigma)\n",
    "        dataset = np.transpose(build_features(image,segments))\n",
    "        data = np.r_[data,dataset]\n",
    "        labeling += labels\n",
    "    return data,labeling\n",
    "\n",
    "def classify(dataset,labels,classifier):\n",
    "    k = 5\n",
    "    n_splits=5\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    skf_ss = StratifiedShuffleSplit(n_splits=n_splits)\n",
    "    C=1\n",
    "    classifiers={\"knn\":KNeighborsClassifier(n_neighbors=k),\"svml\":svm.SVC(kernel='linear', C=C)\n",
    "                 ,\"svmr\":svm.SVC(kernel='rbf', C=C),\n",
    "                   \"boost\":GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                                             max_depth=2, random_state=0)}\n",
    "    scores={}\n",
    "    for k in classifier:\n",
    "        sc= cross_val_score(classifiers[k],dataset,labels,cv=skf)\n",
    "        sc_f= cross_val_score(classifiers[k],dataset,labels,cv=skf)\n",
    "        sc2= cross_val_score(classifiers[k],dataset,labels,cv=skf_ss)\n",
    "        scores[k]=[sc.mean(),sc.std()]\n",
    "        print([sc.mean(),sc.std()])\n",
    "        scores[\"shuffling \"+ k]=[sc2.mean(),sc2.std()]\n",
    "        print([sc2.mean(),sc2.std()])\n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boost': [0.92573099415204685, 0.053456818161527211],\n",
       " 'knn': [0.84093567251461998, 0.03147046560718994],\n",
       " 'shuffling boost': [0.98000000000000009, 0.039999999999999994],\n",
       " 'shuffling knn': [0.90000000000000002, 0.0],\n",
       " 'shuffling svml': [0.91999999999999993, 0.074833147735478819],\n",
       " 'shuffling svmr': [0.90000000000000002, 0.0],\n",
       " 'svml': [0.87192982456140344, 0.10373154736206651],\n",
       " 'svmr': [0.85146198830409359, 0.018713450292397661]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagename= \"horse/rgb/horse001.jpg\"\n",
    "labeling= \"horse/figure_ground/horse001.jpg\"\n",
    "n_segments =100\n",
    "sigma = 5 \n",
    "image,segments,labels=preprocessing(imagename,labeling,n_segments,sigma)\n",
    "dataset=build_features(image,segments)\n",
    "data=np.transpose(dataset)\n",
    "classify(data,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21 Images Example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagespath = \"horse/rgb/\"\n",
    "labelingpath = \"horse/figure_ground/\"\n",
    "data,labels = build_dataset(imagespath,labelingpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67378422682290096, 0.044009288001136189]\n",
      "[0.75824175824175821, 0.012529400275814707]\n",
      "[0.77925444721024839, 0.068476647902948273]\n",
      "[0.85054945054945075, 0.021812564001405726]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boost': [0.77925444721024839, 0.068476647902948273],\n",
       " 'knn': [0.67378422682290096, 0.044009288001136189],\n",
       " 'shuffling boost': [0.85054945054945075, 0.021812564001405726],\n",
       " 'shuffling knn': [0.75824175824175821, 0.012529400275814707]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data,labels,[\"knn\",\"boost\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiler : Timer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrap(*args, **kw):\n",
    "        ts = time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time()\n",
    "        print ('func:%r args:[%r, %r] took: %2.4f sec' % \\\n",
    "          (f.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return wrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_train_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-03377d0d95ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_labeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# number of samples that are initially labeled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrn_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtst_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfully_labeled_trn_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrn_ds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIdealLabeler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_labeled_trn_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_train_test' is not defined"
     ]
    }
   ],
   "source": [
    "test_size = 0.33    # the percentage of samples in the dataset that will be\n",
    "                    # randomly selected and assigned to the test set\n",
    "n_labeled = 10 # number of samples that are initially labeled\n",
    "# Load dataset\n",
    "trn_ds, tst_ds, y_train, fully_labeled_trn_ds = split_train_test(data,labels, test_size, n_labeled)\n",
    "trn_ds2 = copy.deepcopy(trn_ds)\n",
    "lbr = IdealLabeler(fully_labeled_trn_ds)\n",
    "\n",
    "quota = len(y_train) - n_labeled    # number of samples to query\n",
    "\n",
    "# Comparing UncertaintySampling strategy with RandomSampling.\n",
    "# model is the base learner, e.g. LogisticRegression, SVM ... etc.\n",
    "qs = UncertaintySampling(trn_ds, method='lc', model=LogisticRegression())\n",
    "model = LogisticRegression()\n",
    "E_in_1, E_out_1 = run(trn_ds, tst_ds, lbr, model, qs, quota)\n",
    "\n",
    "qs2 = RandomSampling(trn_ds2)\n",
    "model = LogisticRegression()\n",
    "E_in_2, E_out_2 = run(trn_ds2, tst_ds, lbr, model, qs2, quota)\n",
    "\n",
    "# Plot the learning curve of UncertaintySampling to RandomSampling\n",
    "# The x-axis is the number of queries, and the y-axis is the corresponding\n",
    "# error rate.\n",
    "query_num = np.arange(1, quota + 1)\n",
    "plt.plot(query_num, E_in_1, 'b', label='qs Ein')\n",
    "plt.plot(query_num, E_in_2, 'r', label='random Ein')\n",
    "plt.plot(query_num, E_out_1, 'g', label='qs Eout')\n",
    "plt.plot(query_num, E_out_2, 'k', label='random Eout')\n",
    "plt.xlabel('Number of Queries')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Experiment Result')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "       fancybox=True, shadow=True, ncol=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole Dataset -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=np.loadtxt(\"data.txt\")\n",
    "labels=np.loadtxt(\"labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.33    # the percentage of samples in the dataset that will be\n",
    "                    # randomly selected and assigned to the test set\n",
    "n_labeled = 100 # number of samples that are initially labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "active_learning(data,labels,test_size,n_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29234, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75330070053556941, 0.010438276822964209]\n",
      "[0.77346101231190156, 0.0046922224038693765]\n",
      "[0.82698214317999863, 0.015820126882478861]\n",
      "[0.85198358413132702, 0.0055458418059163858]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boost': [0.82698214317999863, 0.015820126882478861],\n",
       " 'knn': [0.75330070053556941, 0.010438276822964209],\n",
       " 'shuffling boost': [0.85198358413132702, 0.0055458418059163858],\n",
       " 'shuffling knn': [0.77346101231190156, 0.0046922224038693765]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(data,labels,[\"knn\",\"boost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
